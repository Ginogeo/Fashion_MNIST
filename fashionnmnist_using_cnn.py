# -*- coding: utf-8 -*-
"""FashionnMNIST_using_CNN.ipynb

Automatically generated by Colaboratory.


    
"""

# Import PyTorch
import torch
from torch import nn

# Import torchvision
import torchvision
from torchvision import datasets
from torchvision import transforms
from torchvision.transforms import ToTensor
import matplotlib.pyplot as plt
from torchvision import datasets

train_data = datasets.FashionMNIST(
    root='data',
    train=True,
    download = True,
    transform = torchvision.transforms.ToTensor(),
    target_transform=None

)
test_data = datasets.FashionMNIST(
    root='data',
    train=False,
    download = True,
    transform = ToTensor(),
    target_transform=None

)
image,label = train_data[0]
image,label

class_names = train_data.classes
class_names
from torch.utils.data import DataLoader
batch_size = 32
train_dataloader = DataLoader(dataset = train_data,
                              batch_size = batch_size,
                              shuffle=True)
test_dataloader = DataLoader(dataset = test_data,
                              batch_size = batch_size,
                              shuffle=False)
train_dataloader,test_dataloader

import requests
from pathlib import Path
if Path ("helper_function.py").is_file():
  print("helper_function already exists")
else :
  print("downloading helper functions")
  requests = requests.get("https://raw.githubusercontent.com/mrdbourke/pytorch-deep-learning/main/helper_functions.py")
  with open ("helper_functions.py", "wb")as f:
    f.write(requests.content)

from helper_functions import accuracy_fn
from torch import nn

from timeit import default_timer as timer
def print_train_time(start:float,
                     end: float,
                     device : torch.device = None):
  total_time = end - start
  print ( f"train time on {device}:{total_time:.3f}seconds")
  return total_time

class FashionMNISTModelV2(nn.Module):
  """
  Model architecture that replicates the TinyVGG
  model from CNN explainer website.
  """
  def __init__(self, input_shape: int, hidden_units: int, output_shape: int):
    super().__init__()
    self.conv_block_1 = nn.Sequential(
        # Create a conv layer - https://pytorch.org/docs/stable/generated/torch.nn.Conv2d.html
        nn.Conv2d(in_channels=input_shape,
                  out_channels=hidden_units,
                  kernel_size=3,
                  stride=1,
                  padding=1), # values we can set ourselves in our NN's are called hyperparameters
        nn.ReLU(),
        nn.Conv2d(in_channels=hidden_units,
                  out_channels=hidden_units,
                  kernel_size=3,
                  stride=1,
                  padding=1),
        nn.ReLU(),
        nn.MaxPool2d(kernel_size=2)
    )
    self.conv_block_2 = nn.Sequential(
        nn.Conv2d(in_channels=hidden_units,
                  out_channels=hidden_units,
                  kernel_size=3,
                  stride=1,
                  padding=1),
        nn.ReLU(),
        nn.Conv2d(in_channels=hidden_units,
                  out_channels=hidden_units,
                  kernel_size=3,
                  stride=1,
                  padding=1),
        nn.ReLU(),
        nn.MaxPool2d(kernel_size=2)
    )
    self.classifier = nn.Sequential(
        nn.Flatten(),
        nn.Linear(in_features=hidden_units*7*7, # there's a trick to calculating this...
                  out_features=output_shape)
    )

  def forward(self, x):
    x = self.conv_block_1(x)
    # print(f"Output shape of conv_block_1: {x.shape}")
    x = self.conv_block_2(x)
    # print(f"Output shape of conv_block_2: {x.shape}")
    x = self.classifier(x)
    # print(f"Output shape of classifier: {x.shape}")
    return x

torch.manual_seed(42)
model_2 = FashionMNISTModelV2(input_shape=1,
                              hidden_units=10,
                              output_shape=len(class_names))

from helper_functions import accuracy_fn
loss_fn = nn.CrossEntropyLoss()
optimizer = torch.optim.SGD(params= model_2.parameters(),
lr=0.1)



def train_step(model: torch.nn.Module,
               data_loader: torch.utils.data.DataLoader,
               loss_fn : torch.nn.Module,
               optimizer: torch.optim.Optimizer,
               accuracy_fn
              ):
  train_loss , train_acc= 0 ,0


  for batch , (x,y) in enumerate (train_dataloader):
    model.train()
    y_pred = model(x)
    loss = loss_fn(y_pred,y)
    train_loss +=loss
    train_acc += accuracy_fn(y_true = y,
                             y_pred=y_pred.argmax(dim=1))
    optimizer.zero_grad()
    loss.backward()
    optimizer.step()
    if batch%400 ==0:

      print(f"looked at {batch*len(x)}/{len(train_dataloader.dataset)}samples.")
  train_loss /= len(data_loader)
  train_acc /= len(data_loader)
  print(f"epochstrainloss:{train_loss:.4f}|trainacc:{train_acc:.4f}")

def test_step(model: torch.nn.Module,
               data_loader: torch.utils.data.DataLoader,
               loss_fn : torch.nn.Module,
               accuracy_fn
              ):

   test_loss,test_acc = 0,0
   model.eval()
   with torch.inference_mode():
     for x_test,y_test in test_dataloader:
       test_pred = model(x_test)
       test_loss += loss_fn(test_pred, y_test)
       test_acc += accuracy_fn(y_true = y_test, y_pred = test_pred.argmax(dim=1))
     test_loss /= len(test_dataloader)
     test_acc /= len(test_dataloader)
     print(f"test_loss:{test_loss:.4f}|test accu :{test_acc:.4f}")

torch.manual_seed(42)

from timeit import default_timer as timer
train_time_start_model_2 = timer()
epochs = 3
for epoch in range(epochs):
  print(f"epoch:{epoch}\n-------")
  train_step ( model= model_2,
                data_loader = train_dataloader,
                loss_fn = loss_fn,
                optimizer = optimizer,
                accuracy_fn = accuracy_fn)
  test_step(    model= model_2,
                data_loader = test_dataloader,
                loss_fn = loss_fn,

                accuracy_fn = accuracy_fn)
train_time_end = timer()
total_train_time = print_train_time(start = train_time_start_model_2,
                                    end = train_time_end
                                  )

def make_pred (model:torch.nn.Module,
               data:list):
   pred_probs = []
   model.eval()
   with torch.inference_mode():
     for sample in data:
       sample = torch.unsqueeze(sample,dim = 0)
       pred_logit = model(sample)
       pred_probs = torch.softmax(pred_logit.squeeze(),dim = 0)
       pred_probs=torch.stack(pred_probs.cpu())
   return torch.stack(pred_probs)

import random
random.seed(42)
test_samples =[]
test_labels = []
for sample , label in random.sample(list(test_data),k=9):
  test_samples.append(sample)
  test_labels.append(label)
test_samples[0].shape

pred_probs = make_pred(model = model_2,
                       data = test_samples)
pred_probs[:2]

from tqdm.auto import tqdm


# 1. Make predictions with trained model
y_preds = []
model_2.eval()
with torch.inference_mode():
  for x, y in tqdm(test_dataloader, desc="Making predictions..."):
    # Send the data and targets to target device

    # Do the forward pass
    y_logit = model_2(X)
    # Turn predictions from logits -> prediction probabilities -> prediction labels
    y_pred = torch.softmax(y_logit.squeeze(), dim=0).argmax(dim=1)
    # Put prediction on CPU for evaluation
    y_preds.append(y_pred.cpu())

# Concatenate list of predictions into a tensor
# print(y_preds)
y_pred_tensor = torch.cat(y_preds)
y_pred_tensor

# See if required packages are installed and if not, install them...
try:
  import torchmetrics, mlxtend
  print(f"mlxtend version: {mlxtend.__version__}")
  assert int(mlxtend.__version__.split(".")[1] >= 19, "mlxtend version should be 0.19.0 or higher")
except:
  !pip install torchmetrics -U mlxtend
  import torchmetrics, mlxtend
  print(f"mlxtend version: {mlxtend.__version__}")

import mlxtend
print(mlxtend.__version__)

from torchmetrics import ConfusionMatrix
from mlxtend.plotting import plot_confusion_matrix

# 2. Setup confusion instance and compare predictions to targets
confmat = ConfusionMatrix(num_classes=len(class_names),task='multiclass')
confmat_tensor = confmat(preds=y_pred_tensor,
                         target=test_data.targets)

# 3. Plot the confusion matrix
fig, ax = plot_confusion_matrix(
    conf_mat=confmat_tensor.numpy(), # matplotlib likes working with numpy
    class_names=class_names,
    figsize=(10, 7)
)

"""#Loading the model"""

from pathlib import Path
model_path = Path("models")
model_path.mkdir(parents = True , exist_ok = True)
model_name = "FashionnMNIST_using_CNN.pth"
model_save_path = model_path/model_name
print(f"Saving model to :{model_save_path}")
torch.save(obj= model_2.state_dict(),
           f=model_save_path)

torch.manual_seed(42)
loaded_model_2 = FashionMNISTModelV2(input_shape= 1,
                                     hidden_units = 10,
                                     output_shape = len(class_names))
loaded_model_2.load_state_dict(torch.load(f=model_save_path))
loaded_model_2.to('cpu')

mode_2_results

